---
title: "Module 2: Overfishing"
format: pdf
editor: source
editor_options: 
  chunk_output_type: inline
---

```{r}
#| warning: false
library(tidyverse)
```


### Use of GitHub

Link to your forked GH repository:

### Use of Quarto

Link to your .qmd file:

## Overexploitation of global fisheries

We will examine the state of global fisheries and seek to reproduce one of the most widely cited examples of species collapse in order to examine the evidence behind an influential paper on global fisheries, [Worm et al. 2006](https://doi.org/10.1126/science.1132294). However, rather than using the 1950-2003 dataset available to Worm and colleagues in 2006, we will be drawing from more recent stock assessment data to see how the trends have fared, specifically in Atlantic cod.

We also explore how to understand and manipulate tabular data using relational database concepts. Instead of working with a single independent dataframe, as in Module 1, we will be working with a large relational database consisting of tables of different dimensions, but are related through one or more IDs.

## The Database

We will use data from the [RAM Legacy Stock Assessment Database](https://www.ramlegacy.org/database/). Note that the database files are available through Zenodo; please download and unzip the file, moving the .RData file only into your own `data/` folder within this project.

Use the code below to load up the tables in this database.

```{r}
load("data/DBdata[asmt][v4.66].RData")
```

The above function loads all 60 tables of this database, which is a lot! So step one of the data science process is exploring the structure of the database and figuring out how the tables are related.

A selected set of documentation have been provided in `documentation/`. Open up the Database Quickstart Guide for reference as you work through the problems below.

### Q1 (1 point)

One of the main metadata tables is 'stock':

-   How many stocks are there and how many species do they represent?

-   What are the top three most common stocks? (Okay to use common names; these are standardized for fish)

-   In your own words, describe the unit of observation in the 'stock' table and some associated variables that describe it.

```{r}
#get number of stocks
nrow(stock)

#get number of species
length(unique(stock$commonname))

#see how many of each species there are
stock |> group_by(commonname) |> summarize(Number = n()) |>arrange(desc(Number))

```

There are 1514 stocks, representing 410 unique species. The species with the most stocks are Pink salmon (170 stocks), Sockeye salmon (104 stocks), and Chum salmon (99 stocks).

The unit of observation in the stocks table seems to be one population of a particular species. A stock is associated with a specific species and a specific location; and also has additional variables describing more details of the location (region or country of that location)  Each stock has a specific stock id and area id which can be used to index into some of the other tables.s

### Q2 (1 point)

The next main metadata table is 'assessment':

-   What is the unit of observation in the 'assessment' table? How is this related to the unit of observation in the 'stock' table?

-   It seems like 'stockid' and 'assessyear' might uniquely identify each assessment. Is this the case? If not, why not?

-   Which variable(s) might you use to join 'stock' and 'assessment'?

The unit of observation in the assessment table is a given assessment of a stock (species+location, as above). So, each stock (unit of observation in the stock table) has some number of assessments of that stock in the assment table.

```{r}
#check if there are any duplicate assessyears for any stockid
assessment |> group_by(stockid) |> summarize(duplicates = n() - n_distinct(assessyear)) |> arrange(desc(duplicates))

#look at the stock with duplicates
assessment |> filter(stockid == "GHALBSAI")
```

We can see that stockid and assessyear do not uniquely identify an assessment, because for the GHALBSAI stock ("Greenland halibut Bering Sea and Aleutian Islands") there are two separate assessments of that stock with years 1960-2020 and two with years 1945-2018; these assesments have different recorders (SISIMP2021 and SISIMP2021-2).

I would join stock and assessment using stockid, to represent that each stock in stock (uniquely identified by stockid) has some number of rows in assessment (and the rows in assessment corresponding to that stock are identified by the value of stockid).

### Q3 (1 point)

In section B of the Database Quick Guide, additional metadata tables are listed in section B. With your data exploration skills, complete the following table:

| B table      | Associated table | join column from B | join column from other |
|--------------|------------------|--------------------|------------------------|
| area         | stock            |    areaid          |       areaid           |
| assessmethod | assessment       |    methodshort     |    assessmethod        |
| assessor     | assessment       |    assessorid      |    assessorid          |
| management   | assessor         |    mgmt            |        mgmt            |
| taxonomy     |  stock           |   scientificname   |    scientificname      |

\*Note that assessmethod is not a data.frame, which was perhaps an oversight; consider turning it into one for the ease of using tidyverse functions.

```{r}
assessmethod <- data.frame(assessmethod)
```

Note that I might be wrong about what the intended associated table is, because some of these tables could be reasonably associated with multiple other tables, for example assessor is associated with both management through mngmt and assessment through assessorid.

### Q4 (1 point)

There are two main data tables described in section C, but their key attributes are difficult to understand. Join the two main data tables with their respective metrics tables (section D):

-   Briefly describe the contents of each joined table.

-   What is accomplished by joining these tables?

```{r}
#confirm that timeseries and tsmetrics can be joined on tsid and tsuniqe respectively
timeseries |> group_by(tsid) |> summarize(count = n()) |> arrange(tsid)
tsmetrics |> group_by(tsunique) |> summarize(count = n()) |> arrange(tsunique)

#join the two; 
#left join on time series because we need to add the metrics corresponding to a given type of time series to that time series row
# there are more rows in timeseries than timeseries metrics and we want to keep those rows
timeseries_with_metrics <- timeseries |> left_join(tsmetrics, join_by(tsid == tsunique))
```
```{r}
#confirm that bioparams and biometrics can be joined on bioid and biounique respectively
bioparams |> group_by(bioid) |> summarize(count = n()) |> arrange(bioid)
biometrics |> group_by(biounique) |> summarize(count = n()) |> arrange(biounique)

#join the two; 
#left join on bioparams because we need to add the metrics corresponding to a given type of parameter to that parameter row
# there are more rows in bioparams than biometrics and we want to keep those rows
bioparams_with_metrics <- bioparams |> left_join(biometrics, join_by(bioid == biounique))
```
For the joined timeseries with metrics, the observational unit is one year of a timeseries that is available in the relational database, stored with the assessment its from (which we can use to join with assessments), the stock its about, the year it has data for and the value of that data. After joining with metrics, the row also has information about what type of time series it is; aka what quantity the value is measuring and what units the measurements are in. This allows all the metadata for all available time series to be in one table.

For the joined bioparams with metrics, the observational unit is as far as I can tell one parameter of a species that is used in a given assessment (ie fecundity, age of 50% maturity); I believe these are parameters that are some way used in whatever modeling goes into the creation of the data by the assessment. After joining the metrics, there is also more information about what the parameter is and what its units are. Again, this essentially allows all the information about parameters used by all the assessments to be in one table.


## Overexploitation of Atlantic cod

This database is clearly complex and contains a lot of information. We've grappled with its high dimensionality by exploring and joining tables above. Next, we will take a "bottom-up" approach and evaluate a single species, Atlantic cod. Read this [book chapter](https://pressbooks.pub/extinctionstories/chapter/atlantic-cod/) on Atlantic cod, which serves as a reference for the following questions.

### Q5 (1 point)

The collapse of the Atlantic cod fisheries is well documented. Let's see if we can visualize that decline with this database. 

-   How many unique fish stocks comprise "Atlantic cod" and what regions do they come from?


Create a vector of the 'stockid' associated with "Atlantic cod". Then turn your attention to the previously-joined timeseries/tsmetrics table and create a subsetted dataframe with only observations of "Atlantic cod" that have a non-NA value. This table reports many years and many metrics, while we are primarily interested in the years since 1950.

-   Which metrics are most commonly reported for Atlantic cod in this timeframe and what do they mean?


```{r}
#Count the stock that have common name Atlantic cod
stock |> filter(commonname == "Atlantic cod") |> summarize(count = n())

#Group by region
stock |> filter(commonname == "Atlantic cod") |> group_by(region) |> summarize(count = n())

```

There are 28 unique stocks of Atlantic cod, coming from the regions of Canada East Coast, Europe non EU, European Union, and the US East Coast.

```{r}
# Get vector of the stockids that are Atlantic Cod
Cod_IDs <- stock |> filter(commonname == "Atlantic cod") |> pull(stockid)

#Get Timeseries (+ metrics) dataframe that are atlantic cod and nonNA value
Cod_ts <- timeseries_with_metrics |> filter(stockid %in% Cod_IDs & !is.na(tsvalue)) 

#Look at metrics reported for years after 1950:
Cod_ts |> filter(tsyear > 1950) |> group_by(tsid) |> summarize(metric_count = n(), meaning = first(tslong)) |> arrange(desc(metric_count))
```

The 5 most commonly reported metrics in this time frame are CdivMEANC-ratio, TCbest-MT, TL-MT, SSB-MT, and R-E00. Respectively, these represent the catch divided by mean catch (basically, normalized catch); general total catch (total catch if available, total landings if not available, guaranteed to use metric tons); total landings (I believe this means the number of caught and non released cod), spawning stock biomass (according to the international seafood sustainability foundation (ISSF), the total weight of all sexually mature female cod), and recruits (according to the ISSF, the number of fish in the youngest age group that is still considered exploitable by fisheries). Also note that the top two metrics (normalized catch and general total catch) have the same number of nonna time series values (7055).

### Q6 (1 point)

Make a timeseries figure for each stock of Atlantic cod. Rather than coloring by the identity of the stock, color by the region it comes from (this may require joining). Use `facet_*()` to plot both metrics in a single code chunk. Connect the points for each stock and focus on the period since 1950. Update until the figure is easily interpretable.


-   What happened to Atlantic cod stocks during the period 1950-present? What information does each metric convey?

(I assume when you say both metrics you mean the top two most commonly reported metrics; normalized catch and total catch?)

I assume that despite it being implied by the wording, you do not want a unique figure for each stock (ie 28 separate figures which would not be easily interpretable at all) but to have separate lines for each stock colored by region. Just in case you did want that though, I made a version with 28 different figures as well.

```{r}
#join the stock df to the Cod_ts df so that we have region
Cod_to_plot <- left_join(Cod_ts, stock, join_by(stockid == stockid))

#Then keep only the metrics we're plotting and only the years after 1950
Cod_to_plot <- Cod_to_plot |> filter((tsid == "CdivMEANC-ratio" | tsid == "TCbest-MT") & tsyear > 1950)

#I looked into stack overflow answers to figure out how to customize the plot properly

Cod_to_plot |> ggplot(aes(x = tsyear, y = tsvalue, color = region, group = stockid)) +
  geom_point(size = 0.5) + geom_line() + facet_grid(tsid~., scales = "free", switch = "y", 
                labeller = as_labeller(c("CdivMEANC-ratio" = "Catch: Mean Catch ratio", "TCbest-MT" = "Total Catch (metric tons)"))) + scale_color_manual(values = c("Canada East Coast" = "red", "Europe non EU" = "darkgreen", "European Union" = "lightblue", "US East Coast" = "purple"), drop = FALSE) +
                  labs(x = "Year", color = "Region") + theme_bw() + theme(axis.title.y = element_blank(), strip.placement = "outside") 
```

And as promised the version with 28 separate plots, in case "figure for each stock" was intended to imply a separate figure for each plot; in this case I group the lines by assessment for interpretability. Unfortunately I could not find a way to have the same y scale for all plots while using facet_wrap. I do think this is a significantly less interpretable version, but the wording of the question was unclear to me.
```{r}
for (id in Cod_IDs) {
  plot <- Cod_to_plot |> filter(stockid == id) |> ggplot(aes(x = tsyear, y = tsvalue, color = region, group = assessid)) + scale_color_manual(values = c("Canada East Coast" = "red", "Europe non EU" = "green", "European Union" = "lightblue", "US East Coast" = "orange"), drop = FALSE) + 
          geom_point(size = 0.5, show.legend = TRUE) + geom_line() + facet_grid(tsid~., scales = "free", switch = "y", 
              labeller = as_labeller(c("CdivMEANC-ratio" = "Catch: Mean Catch ratio", "TCbest-MT" = "Total Catch (metric tons)")))  + xlims(1950, 2022) + 
              labs(x = "Year", color = "Region") + theme_bw() + theme(axis.title.y = element_blank(), strip.placement = "outside",) 
  print(plot)
}
```

We can see that in the period from 1950 to 2022, total catches of Atlantic cod populations have decreased for most stocks. The top figure shows the normalized cod catch, which makes it easier to look at the change over time of each catch compared to looking at the absolute mean catch (where some stocks simply have much larger catches at all times than others). Looking at that figure, we can see that almost all stocks had above mean catch (normalized catch > 1) in the earlier portion of the 20th century and below mean catch (normalized catch < 1) in recent decades, demonstrating the decrease in catch over time.


### Q7 (1 point)

We will recreate a slightly more complex version of a figure from the [Millennium Ecosystem Assessment](https://www.millenniumassessment.org/documents/document.356.aspx.pdf) (Fig. 11).

Selecting a metric that can be added across stocks, calculate the total fish landings for each region of Atlantic cod. Make a plot similar to Fig. 11 and color by region.


Which region does Fig. 11 from the MEA correspond to?

### Q8 (1 point)

Under the Management Policies section of the [book chapter](https://pressbooks.pub/extinctionstories/chapter/atlantic-cod/), the authors summarize a few major efforts to restore and protect stocks of Atlantic cod. Focusing only on the US and Canada, update your plot from above to include vertical lines to represent the timing of least three major events and label them clearly on your plot. Doing so will likely involve creating a separate dataframe and using it in one of your ggplot layers (one possible argument within `aes()` is `linetype`). Facet the plot by region and update until it is easily interpretable.

### Q9 (2 points)

What happened to Atlantic cod stocks for each region following each piece of legislation or management plan, and why do you think this was so? Your multi-paragraph answer should be informed by content from the book chapter; additional sources are optional, and all sources should be cited.
